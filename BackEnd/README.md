# VoiceGate Backend

<div align="center">

![VoiceGate Logo](https://img.shields.io/badge/VoiceGate-AI%20Assistant-blueviolet)
![FastAPI](https://img.shields.io/badge/FastAPI-0.104.0-green)
![Python](https://img.shields.io/badge/Python-3.9+-blue)
![MongoDB](https://img.shields.io/badge/MongoDB-7.0-green)

**Assistant vocal intelligent avec reconnaissance du locuteur en temps rÃ©el**

[Documentation API](http://127.0.0.1:8002/docs) â€¢ [Installation](#-installation) â€¢ [Utilisation](#-utilisation) â€¢ [API Reference](#-rÃ©fÃ©rence-api)

</div>

## ğŸŒŸ PrÃ©sentation

VoiceGate est un assistant vocal intelligent capable de :
- ğŸ¤ **ReconnaÃ®tre les locuteurs** via empreintes vocales (ECAPA-TDNN)
- ğŸ“ **Transcrire la parole** en texte avec Whisper
- ğŸ’¬ **Dialoguer intelligemment** avec reconnaissance d'intention
- ğŸ”Š **RÃ©pondre oralement** avec synthÃ¨se vocale multi-moteurs
- âš¡ **Fonctionner en temps rÃ©el** via WebSocket

**Architecture :** FastAPI + MongoDB + Whisper + WebSocket

## ğŸš€ Installation Rapide

### PrÃ©requis
```bash
Python 3.9+ | FFmpeg | MongoDB (optionnel)
```

### 1. Cloner le projet
```bash
git clone https://github.com/fabrice002/VoiceGate_TDM.git
cd BackEnd
```

### 2. Configuration
```bash
# Copier le fichier d'environnement
cp .env.example .env

# Ã‰diter .env (optionnel)
nano .env
```

### 3. Installation avec Poetry (recommandÃ©)
```bash
# Installer Poetry
curl -sSL https://install.python-poetry.org | python3 -

# Installer les dÃ©pendances
poetry install

# Activer l'environnement virtuel
poetry shell
```

### 4. Installation avec pip
```bash
pip install -r requirements.txt
```

### 5. Lancer le serveur
```bash
# Mode dÃ©veloppement
python -m uvicorn app.main:app --reload --host 127.0.0.1 --port 8002

# Mode production
gunicorn -w 4 -k uvicorn.workers.UvicornWorker app.main:app
```

## ğŸ“ Structure du Projet

```
voicegate-backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # Point d'entrÃ©e FastAPI
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py        # Configuration
â”‚   â”‚   â””â”€â”€ database.py      # MongoDB + Mock DB
â”‚   â”œâ”€â”€ api/routes/          # Routes API
â”‚   â”œâ”€â”€ services/           # Services mÃ©tier
â”‚   â”œâ”€â”€ models/             # ModÃ¨les Pydantic
â”‚   â””â”€â”€ schemas/            # SchÃ©mas API
â”œâ”€â”€ data/                   # DonnÃ©es persistantes
â”‚   â”œâ”€â”€ mock_db/           # Base de donnÃ©es mock
â”‚   â”œâ”€â”€ voice_embeddings/  # Empreintes vocales
â”‚   â””â”€â”€ audio_files/       # Fichiers audio 
```

## ğŸ”§ Configuration

### Variables d'environnement (.env)
```env
# Application
APP_NAME=VoiceGate AI Assistant
DEBUG=True
PORT=8002

# Base de donnÃ©es
MONGODB_URI=mongodb://localhost:27017
MONGO_DB_NAME=voicegate_db
USE_MONGODB=False  # True pour MongoDB, False pour Mock DB

# ModÃ¨les AI
WHISPER_MODEL=base
WHISPER_LANGUAGE=fr
ECAPA_MODEL=speechbrain/spkrec-ecapa-voxceleb
HF_MODEL_NAME=microsoft/DialoGPT-small

# Paths
VOICE_DB_FOLDER=data/voice_embeddings
AUDIO_STORAGE_PATH=data/audio_files
```

## ğŸ¯ Utilisation

### 1. VÃ©rifier l'installation
```bash
curl http://127.0.0.1:8002/health
# RÃ©ponse: {"status": "healthy", "database": "Mock"}
```

### 2. CrÃ©er un utilisateur
```bash
curl -X POST http://127.0.0.1:8002/api/users/ \
  -H "Content-Type: application/json" \
  -d '{"username": "alice", "email": "alice@example.com"}'
```

### 3. Enregistrer une voix
```bash
curl -X POST http://127.0.0.1:8002/api/voice/register \
  -F "username=alice" \
  -F "file=@voix.wav"
```

### 4. Tester la reconnaissance vocale
```bash
curl -X POST http://127.0.0.1:8002/api/assistant/process \
  -F "file=@audio_test.wav"
```

### 5. Utiliser le pipeline complet
```python
import requests

# 1. Transcrire
transcription = requests.post(
    "http://127.0.0.1:8002/api/transcription/transcribe",
    files={"file": open("audio.wav", "rb")},
    data={"language": "fr"}
).json()

# 2. GÃ©nÃ©rer rÃ©ponse TTS
tts_response = requests.post(
    "http://127.0.0.1:8002/api/tts/generate",
    json={
        "text": f"Bonjour! Vous avez dit: {transcription['text']}",
        "language": "fr"
    }
).json()

print(f"Audio gÃ©nÃ©rÃ©: {tts_response['audio_url']}")
```

## ğŸ“¡ RÃ©fÃ©rence API

### Endpoints Principaux

| MÃ©thode | Endpoint | Description |
|---------|----------|-------------|
| **GET** | `/` | Page d'accueil avec statut |
| **GET** | `/docs` | Documentation Swagger |
| **GET** | `/health` | SantÃ© du systÃ¨me |

### ğŸ‘¤ Gestion Utilisateurs
- `POST /api/users/` - CrÃ©er un utilisateur
- `GET /api/users/` - Lister les utilisateurs
- `GET /api/users/{username}` - Obtenir un utilisateur
- `DELETE /api/users/{username}` - Supprimer un utilisateur

### ğŸ¤ Reconnaissance Vocale
- `POST /api/voice/register` - Enregistrer empreinte vocale
- `POST /api/voice/identify` - Identifier un locuteur

### ğŸ“ Transcription
- `POST /api/transcription/transcribe` - Transcrire audio
- `POST /api/transcription/transcribe-base64` - Transcrire audio base64

### ğŸ’¬ Conversation
- `POST /api/voice-conversation/voice-ask` - Pipeline complet voixâ†’rÃ©ponse
- `GET /api/voice-conversation/conversations/{user_id}/voice` - Historique

### ğŸ”Š Text-to-Speech
- `POST /api/tts/generate` - GÃ©nÃ©rer audio depuis texte
- `GET /api/tts/stream` - Stream audio en direct

### âš¡ WebSocket Temps RÃ©el
- `WS /ws/ws/audio/{user_id}` - Streaming audio bidirectionnel
- `WS /ws/ws/logs` - Logs temps rÃ©el
- `WS /ws/ws/monitoring` - MÃ©triques temps rÃ©el



## ğŸ› DÃ©pannage

### ProblÃ¨mes courants

1. **Erreur "FFmpeg not found"**
   ```bash
   # Ubuntu/Debian
   sudo apt install ffmpeg
   
   # macOS
   brew install ffmpeg
   
   # Windows (choco)
   choco install ffmpeg
   ```

2. **Port dÃ©jÃ  utilisÃ©**
   ```bash
   # Changer le port dans .env
   PORT=8003
   ```

3. **Base de donnÃ©es non connectÃ©e**
   ```bash
   # VÃ©rifier MongoDB
   mongod --version
   
   # Ou utiliser Mock DB
   USE_MONGODB=False
   ```

4. **ModÃ¨les non tÃ©lÃ©chargÃ©s**
   ```bash
   # Les modÃ¨les se tÃ©lÃ©chargent automatiquement
   # VÃ©rifier le dossier data/pretrained_models/
   ```

## ğŸ“ˆ Monitoring

### Dashboard intÃ©grÃ©
- AccÃ©der Ã : `http://127.0.0.1:8002/api/monitoring/metrics`
- MÃ©triques en temps rÃ©el: latence, succÃ¨s, performance

### Logs
```bash
# Mode debug
DEBUG=True

# Voir les logs
tail -f logs/app.log
```

## ğŸš€ DÃ©ploiement

### Docker
```dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .

CMD ["gunicorn", "-w", "4", "-k", "uvicorn.workers.UvicornWorker", "app.main:app"]
```

### Docker Compose
```yaml
version: '3.8'
services:
  voicegate:
    build: .
    ports:
      - "8002:8002"
    environment:
      - MONGODB_URI=mongodb://mongodb:27017
      - USE_MONGODB=True
    depends_on:
      - mongodb

  mongodb:
    image: mongo:latest
    ports:
      - "27017:27017"
    volumes:
      - mongodb_data:/data/db

volumes:
  mongodb_data:
```

## ğŸ“š Documentation Additionnelle

- [Guide Whisper](docs/whisper_guide.md)
- [API Swagger](http://127.0.0.1:8002/docs)
- [SchÃ©ma Base de DonnÃ©es](docs/database_schema.md)
- [Architecture](docs/architecture.md)

## ğŸ¤ Contribution

1. Fork le projet
2. CrÃ©er une branche (`git checkout -b feature/amazing`)
3. Commit (`git commit -m 'Add amazing feature'`)
4. Push (`git push origin feature/amazing`)
5. Ouvrir une Pull Request

## ğŸ“„ Licence

MIT License - Voir le fichier [LICENSE](LICENSE)

## ğŸ™ Remerciements

- [OpenAI Whisper](https://github.com/openai/whisper) pour la transcription
- [SpeechBrain](https://speechbrain.github.io/) pour ECAPA-TDNN
- [FastAPI](https://fastapi.tiangolo.com/) pour le backend
- [FFmpeg](https://ffmpeg.org/) pour le traitement audio



---

<div align="center">
  
**VoiceGate** - Votre assistant vocal intelligent

[â¬† Retour en haut](#voicegate-backend)

</div>